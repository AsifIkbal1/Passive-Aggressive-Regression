{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# standard libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport warnings, gc\nwarnings.simplefilter('ignore')\n\n# sklearn\nfrom sklearn.model_selection import *\nfrom sklearn.metrics import *\nfrom sklearn.linear_model import *\nfrom sklearn.cluster import *\nfrom sklearn.preprocessing import *\nfrom sklearn.pipeline import *\nfrom sklearn.compose import *\nfrom sklearn.utils import *","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-24T01:21:10.083731Z","iopub.execute_input":"2023-08-24T01:21:10.084143Z","iopub.status.idle":"2023-08-24T01:21:10.090879Z","shell.execute_reply.started":"2023-08-24T01:21:10.084113Z","shell.execute_reply":"2023-08-24T01:21:10.089695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load Data","metadata":{}},{"cell_type":"code","source":"# load\nCSV = '/kaggle/input/medical-cost-dataset/medical_cost.csv'\ndf = pd.read_csv(CSV)\n\n# remove ID column\ndf = df.iloc[:,1:]\n\n# format decimal \ndf['bmi'] = df['bmi'].apply(lambda x: round(x,2))\ndf['charges'] = df['charges'].apply(lambda x: round(x,2))\n\n# categorical features\ncat_cols = ['sex', 'smoker', 'region']\nfor c in cat_cols:\n    df[c] = df[c].astype('category')\n    \n# converting categorical features to codes\ndf[cat_cols] = df[cat_cols].apply(lambda x: x.cat.codes)\n\n# view\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-24T01:21:12.891025Z","iopub.execute_input":"2023-08-24T01:21:12.891461Z","iopub.status.idle":"2023-08-24T01:21:12.963752Z","shell.execute_reply.started":"2023-08-24T01:21:12.891426Z","shell.execute_reply":"2023-08-24T01:21:12.962678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### De-Duplication","metadata":{}},{"cell_type":"code","source":"# find duplicate rows\nduplicate = df[df.duplicated(subset=df.columns[:-1].tolist())]\nduplicate","metadata":{"execution":{"iopub.status.busy":"2023-08-24T01:21:17.516459Z","iopub.execute_input":"2023-08-24T01:21:17.517702Z","iopub.status.idle":"2023-08-24T01:21:17.543011Z","shell.execute_reply.started":"2023-08-24T01:21:17.517654Z","shell.execute_reply":"2023-08-24T01:21:17.541705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**I have 2 options here,**\n\n1. **drop duplicates (easy)**\n2. **merge duplicates (little tricky)**\n\n**I will go with option#2. The aggregate strategy that I'm going to use is MEAN.**","metadata":{}},{"cell_type":"code","source":"# merge duplicates\ndf = df.groupby(df.columns[:-1].tolist()).agg({'charges': np.mean}).reset_index()","metadata":{"execution":{"iopub.status.busy":"2023-08-24T01:21:19.71336Z","iopub.execute_input":"2023-08-24T01:21:19.71413Z","iopub.status.idle":"2023-08-24T01:21:19.732073Z","shell.execute_reply.started":"2023-08-24T01:21:19.714085Z","shell.execute_reply":"2023-08-24T01:21:19.731138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Cluster Feature","metadata":{}},{"cell_type":"code","source":"# creating a seperate dataset for cluster features\ntemp = df.copy()\ncluster_feat = df.columns[:-1].tolist()\ncluster_df = temp.groupby(by=cluster_feat, as_index=False)['charges'].mean()\n\n\n# applying cluster algorithm\nkwargs = {\n        \"init\": 'k-means++',\n        \"random_state\": np.random.randint(10),\n        \"max_iter\": 100,\n        \"bisecting_strategy\": 'largest_cluster',\n        }\n\nsil_scores = {}\nfor n in range(2, 10):\n    clust = BisectingKMeans(n_clusters=n, **kwargs)\n    labels = clust.fit_predict(cluster_df)\n    sil_scores[n] = round(silhouette_score(cluster_df, labels), 3)\n\n    \n# get the n_cluster with highest silhouette score\nsil_score_max = max(sil_scores.values())\nn_cluster = [key for key, val in sil_scores.items() if val == sil_score_max]\n\n\n# applying the cluster to the dataset\ncluster_df['cluster_feat'] = BisectingKMeans(n_clusters=n_cluster[0], **kwargs).fit(cluster_df).labels_\n\n\n# merge the dataset\ndf = pd.merge(df, cluster_df, right_on=cluster_feat, left_on=cluster_feat)\n\n\n# drop (one of the) charges column\ndf.drop('charges_y', axis=1, inplace=True)\n\n\n# rename charges column\ndf.rename(columns={'charges_x': 'charges'}, inplace=True)\n\n\n# view\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-24T01:21:23.318934Z","iopub.execute_input":"2023-08-24T01:21:23.3194Z","iopub.status.idle":"2023-08-24T01:21:25.50458Z","shell.execute_reply.started":"2023-08-24T01:21:23.319361Z","shell.execute_reply":"2023-08-24T01:21:25.503175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Convert Age to Category","metadata":{}},{"cell_type":"code","source":"# generic age categories\n# Baby/Toddler: (0,3], 0 is excluded & 3 is included\n# Child: (3,17], 3 is excluded & 17 is included\n# Adult: (17,63], 17 is excluded & 63 is included\n# Elderly: (63,99], 63 is excluded & 99 is included\n\ndf['age'] = pd.cut(x=df['age'], bins=[0, 3, 17, 63, 99],\n                     labels=[\n                              0,  #'Baby/Toddler', \n                              1,  # 'Child', \n                              2,  #'Adult',\n                              3  #'Elderly'\n                           ])","metadata":{"execution":{"iopub.status.busy":"2023-08-24T01:21:29.446233Z","iopub.execute_input":"2023-08-24T01:21:29.446666Z","iopub.status.idle":"2023-08-24T01:21:29.457656Z","shell.execute_reply.started":"2023-08-24T01:21:29.44663Z","shell.execute_reply":"2023-08-24T01:21:29.456478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature Engineering","metadata":{}},{"cell_type":"code","source":"# features & target\nx,y = df.drop('charges',axis=1, inplace=False), df[['charges']]\n\n# train & test split\nsplit = 0.1\nx_train, x_val, y_train, y_val = train_test_split(x,y, test_size=split, shuffle=True)\nprint(f\"Training size: {x_train.shape[0]}\\nValidation size: {x_val.shape[0]}\")","metadata":{"execution":{"iopub.status.busy":"2023-08-24T01:21:33.375811Z","iopub.execute_input":"2023-08-24T01:21:33.376224Z","iopub.status.idle":"2023-08-24T01:21:33.389836Z","shell.execute_reply.started":"2023-08-24T01:21:33.376189Z","shell.execute_reply":"2023-08-24T01:21:33.388731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Base Regressor Pipeline","metadata":{}},{"cell_type":"code","source":"# list of numeric columns\nnum_cols = ['bmi']\ncat_cols = ['age', 'sex', 'children', 'smoker', 'region', 'cluster_feat']\n\n# base regressor\nregressor = PassiveAggressiveRegressor()\n\n# numerical column transformer\nnum_transformer = Pipeline(steps=[(\"scale\", StandardScaler())])\n\n# categorical column transformer\ncat_transformer = Pipeline(steps=[(\"encode\", OneHotEncoder(handle_unknown='ignore'))])\n\n# pre-processor pipeline\npreprocessor = ColumnTransformer(transformers=\n        [\n           (\"num\", num_transformer, num_cols),\n            (\"cat\", cat_transformer, cat_cols)\n        ])\n\n# build a regression pipeline\nreg_pipe = Pipeline(steps=[\n                            (\"preprocess\", preprocessor),\n                            (\"regressor\", regressor)\n])\n\n# fit the training data\nreg_pipe.fit(x_train, y_train)\n\n# make prediction\ny_pred = reg_pipe.predict(x_val)\nmae = '{:.3f}'.format(mean_absolute_error(y_val, y_pred))\nprint(f\"MAE of our base regressor: {mae}\")","metadata":{"execution":{"iopub.status.busy":"2023-08-24T01:24:03.455658Z","iopub.execute_input":"2023-08-24T01:24:03.456096Z","iopub.status.idle":"2023-08-24T01:24:03.520038Z","shell.execute_reply.started":"2023-08-24T01:24:03.456065Z","shell.execute_reply":"2023-08-24T01:24:03.518776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**That's a pathetic !!, I'll try to fine tune the hyperparameters**\n\n<br>\n\n### Tuning Hyperparameters","metadata":{}},{"cell_type":"code","source":"# param grid\n\nparam_grid = {\n        # Huber Regressor Hyperparameters    \n        \"regressor__C\": np.linspace(1,5, 5, dtype=np.float64).tolist(),\n        \"regressor__max_iter\": np.linspace(1000,3000, 5, dtype=np.int64).tolist(),\n        \"regressor__tol\": [1e-1, 1e-2, 1e-3, 1e-4, 1e-5],\n        \"regressor__validation_fraction\": np.linspace(0, 1,5, dtype=np.float64).tolist()\n    }","metadata":{"execution":{"iopub.status.busy":"2023-08-24T01:30:40.755658Z","iopub.execute_input":"2023-08-24T01:30:40.756275Z","iopub.status.idle":"2023-08-24T01:30:40.764555Z","shell.execute_reply.started":"2023-08-24T01:30:40.756233Z","shell.execute_reply":"2023-08-24T01:30:40.763223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# grid search\ngrid = GridSearchCV(reg_pipe, n_jobs=-1, param_grid=param_grid, verbose=0)\n\n# fit data\ngrid.fit(x_train, y_train)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('*'*100)\nprint(f\"\\nBest Params:{grid.best_params_}\\n\")\nprint(f\"Best Score:{grid.best_score_}\\n\")\nprint('*'*100)","metadata":{"execution":{"iopub.status.busy":"2023-08-24T01:32:55.943387Z","iopub.execute_input":"2023-08-24T01:32:55.943978Z","iopub.status.idle":"2023-08-24T01:32:55.951471Z","shell.execute_reply.started":"2023-08-24T01:32:55.943942Z","shell.execute_reply":"2023-08-24T01:32:55.950317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tuned Base Regressor Pipeline","metadata":{}},{"cell_type":"code","source":"# best params\nbest_params = {'C': 5.0, 'tol': 0.1, 'max_iter': 2500, 'validation_fraction': 0.75}\n\n# tuned regressor\nregressor_tuned = PassiveAggressiveRegressor(**best_params)\n\n# build a new regression pipeline\nreg_pipe_new = Pipeline(steps=[\n                            (\"preprocess\", preprocessor),\n                            (\"regressor\", regressor_tuned)\n])\n\n# fit the training data\nreg_pipe_new.fit(x_train, y_train)\n\n# make prediction\ny_pred = reg_pipe_new.predict(x_val)\nmae = '{:.3f}'.format(mean_absolute_error(y_val, y_pred))\nprint(f\"MAE of our optimized regressor: {mae}\")","metadata":{"execution":{"iopub.status.busy":"2023-08-24T01:36:03.421247Z","iopub.execute_input":"2023-08-24T01:36:03.422476Z","iopub.status.idle":"2023-08-24T01:36:03.463657Z","shell.execute_reply.started":"2023-08-24T01:36:03.422435Z","shell.execute_reply":"2023-08-24T01:36:03.462464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Not a great improvement but will suffice for now !**","metadata":{}}]}